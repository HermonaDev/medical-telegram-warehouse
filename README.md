# ğŸ¥ Medical Telegram Data Warehouse & AI Pipeline

[![Medical Data CI](https://github.com/YOUR_USERNAME/medical-telegram-warehouse/actions/workflows/ci.yml/badge.svg)](https://github.com/YOUR_USERNAME/medical-telegram-warehouse/actions)
![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![dbt](https://img.shields.io/badge/dbt-1.11.2-orange.svg)
![YOLOv8](https://img.shields.io/badge/AI-YOLOv8-green.svg)

An end-to-end Data Engineering pipeline that extracts medical data from Telegram channels, transforms it into a Star Schema warehouse, and enriches it using Computer Vision (YOLOv8).

## ğŸ“Š Pipeline Overview
1. **Extract**: Multi-channel Telegram scraping using `Telethon`.
2. **Load**: Raw data ingestion into a `PostgreSQL` JSONB landing zone (Dockerized).
3. **Transform**: Modular data modeling with `dbt` (Staging -> Marts).
4. **Enrich**: Object detection on medical images using `YOLOv8`.

---

## ğŸ— Project Architecture
```text
â”œâ”€â”€ .github/workflows/   # CI/CD (GitHub Actions)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Scraped JSON and Images
â”‚   â””â”€â”€ yolo_results.csv # CV Inference output
â”œâ”€â”€ kara_dbt/            # dbt Project
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/     # Cleaning & Type Casting
â”‚   â”‚   â””â”€â”€ marts/       # Star Schema (Fact/Dim tables)
â”‚   â””â”€â”€ schema.yml       # Data Documentation & Tests
â”œâ”€â”€ scripts/             # Python ETL & AI Scripts
â”œâ”€â”€ docker-compose.yml   # PostgreSQL Warehouse Setup
â””â”€â”€ requirements.txt     # Dependency Management
```


## ğŸš€ Key Achievements (Interim Report - Jan 17)

* **Ingested**: 482 messages from 7 medical channels.
* **Processed**: 468 objects detected in images (Bottles, Equipment, Labels).
* **Warehouse**: Fully operational PostgreSQL DB with automated dbt transformations.
* **CI/CD**: Integrated GitHub Actions for automated build validation.

## ğŸ›  Setup & Usage

### 1. Environment Setup

```bash
python -m venv venv
source venv/scripts/activate
pip install -r requirements.txt

```

### 2. Database & Warehouse

```bash
docker-compose up -d

```

### 3. Transformation (dbt)

```bash
cd kara_dbt
dbt deps
dbt run
dbt test

```

## ğŸ“ˆ Sample Results

| Channel | Message Text | Detected Item | Confidence |
| --- | --- | --- | --- |
| cafimadEt | Riluzole... | Bottle | 0.74 |
| CheMed123 | Azithromycin... | Person | 0.86 |

---

## âš–ï¸ Code Best Practices

* **Modular SQL**: Used dbt `ref()` and `source()` for dynamic lineage.
* **Scalability**: JSONB storage for flexible schema evolution.
* **Automation**: GitHub Actions for Continuous Integration.
